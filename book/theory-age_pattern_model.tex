\section{Age pattern models}
\label{theory-age_pattern_model}
In this section, I develop the mathematical and statistical theory behind the 
model for age patterns in epidemiological rates.  The motivation for
this is the observation that prevalence, incidence, remission, and
mortality can all vary by orders of magnitude as a function of age.
All-cause mortality rates provide one of the starkest examples, and
also one of the most closely studied.  Figure~\ref{TK} shows the age
pattern of adult mortality for females in the Asia Pacific High Income
regions in 2005.  It is displayed on a semi-log scale to emphasize the
fact that the mortality rate ranges of TK orders of magnitude as age
increases.

TK Figure showing an example of the age pattern
for adult mortality in Asia Pacific High Income Females in 2005.

This
is a good time to point out that these age patterns may vary a great
deal between regions, times, and sexes, TK for example life expectancy
in US counties [ref TK].  However, it is systematic variation as a
function of \emph{age} that is expected to be the largest source of
variation in theory.

In in Bayesian statistical framework that I am using, the design goal
in age pattern modeling is to develop a \emph{prior distribution} on
non-negative functions of age, i.e. a probability density
$\dens(\boldpi\given\theta)$ that is defined on functions
$\boldpi:[0,\infty]\rightarrow[0,\infty]$.  These functions will be used as
the age patterns for flows in the systems dynamics model from
Chapter~\ref{chapter:system-dynamics}.

There are two popular approaches for modeling continuous functions
statistically, splines and Gaussian processes.


It will typically be the case that epidemiologic rates vary as a function of age, and, furthermore, that this variation is not linear. Here, we discuss two popular approaches for flexible statistical modeling of continuous functions: splines and Gaussian processes. 

\subsection{Splines}

\subsubsection{Linear Basis Expansions}

As motivation for our discussion around flexible modeling of continuous variables, consider the simple model relating the conditional mean of some variable $Y$ to a continuous predictor $X$
	\[E[Y \mid X] = f(X),\]
where $f(X)$ is some function of $X$. In the case where $f(X) = \beta_0 + \beta_1 X$, we see that this model returns the familiar and trustworthy simple linear regression of $Y$ on $X$. 

In many cases, the relationship between the conditional mean of $Y$ and $X$ is non-linear (see, for example, the data depicted in Figure \ref{splines_fig}). It is common to tackle this problem my including higher order polynomial transformations of the variable $X$ to capture potential non-linearity. For example, one might consider modeling this relationship using a third degree polynomial
	\[E[Y|X] = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3.\]
While this model can indeed capture potential non-linearity in the relationship between $X$ and $Y$, it is known that polynomial approximations of this type can have erratic behavior at the boundaries of the observed data \cite{ESL}. Furthermore, polynomial regressions may lack the necessary flexibility to capture complex non-linear relationships. As such, a more flexible solution with better behavior is needed.

In both of the above mentioned cases, the functional form of $f(X)$ can be expressed as follows
	\[f(X) = \sum_{i=0}^m\beta_m h_m(X),\]
where $h_i(X)$ is the $m^{th}$ transformation of the variable $X$. For example, we see that
	\begin{itemize}
		\item if $f(X) = \beta_0 + \beta_1 X$, $h_0(X)=1$ and $h_1(X) = X$, and
		\item if $f(X) = \beta_0 + \beta_1 X + \beta_2 X^2 + \beta_3 X^3$, $h_0(X) = 1$, and $h_i(X) = X^i$, for $i=1,2,3$.
	\end{itemize}
The functions $h_i$ represent a linear basis expansion of the variable $X$, and serve to motivate our discussion around flexible modeling. 

Models represented in this way are particularly attractive in that they can be fit using any standard statistical software. One need only provide the set of basis functions or data transformations and estimate the parameters $\beta_i, i=0, M$ using least squares. Namely, we can estimate the regression coefficients, $\beta_m,\; m=0, \dots, M$, for our linear basis functions by minimizing 
	\[\sum_{i=1}^n \left(Y_i - \sum_{m=0}^M \beta_mh_m(X_i)\right)^2.\]

\subsubsection{Regression Splines}

\emph{Regression splines} or \emph{piecewise polynomials} refer to a family of models which result from specifc definitions of the basis functions, $h_i$. These models arise by partitioning the variable $X$ into $k+1$  contiguous intervals at \emph{knot locations} $\xi_1, \dots, \xi_{k}$. The function $f$ is then represented by different polynomials in each interval. The simplest example of this is the representation of $f$ as piecewise constant. In this case, we have
	\[h_0(X) = I(X \leq \xi_1),\; h_1(X)=I(\xi_1 < X \leq \xi_2), \; \dots, h_{k}(X) = I(X > \xi_k).  \]
As we see in Figure \ref{splines_fig}, the resulting fit is a series of horizontal (constant) lines in each of the specified intervals. In particular, we see that in the $m^{th}$ interval, $\hat{\beta}_m = \bar{Y}_m$, or the mean value of $Y$ in that interval.

A more favorable and flexible fit to the data might be achieved by instead representing the data in each interval as a line, i.e. fitting a piecewise linear model to the data. This can be achieved by the following basis,
	\[h_0(X) = 1,\; h_1(X) = X,\; h_2(X) = (X- \xi_1)_+,\; \dots,\; h_{k+2}=(X-\xi_k)_+,\]
where the notation $h_+$ indicates the positive part of $h$. Models fit using bases of this type are continuous but not differentiable at the knot locations, as seen in  Figure \ref{splines_fig}. In many cases, a piecewise linear fit of this type is sufficient to capture any non-linearity in the data. However, a popular alternative which yields ``smooth'' curves to the data are piecewise cubic polynomials. These type of regression splines ensure first and second order differentiability at the knot locations and yielding aethetically pleasing fits at the expense of more parameters.

We note that piecwise polynomial splines provide a useful tool for flexible modeling of non-linear trends. However, it should also be said that piecewise polynomial regressions tend to have the same issues as polynomial regressions at the boundaries of the data. One solution to this issue is to require that the fit is \emph{linear} beyond the range of the data. Imposing these constraints results in the \emph{natural spline}. The benefit of using natural splines is that the imposed constraints yield two extra free parameters, which can perhaps be more efficiently used by selecting two more interior knots. Thus, the natural spline allows for more potential interior flexibility of your fit with the same level of model complexity as its piecewise polynomial counterpart.

Indeed, a wealth of literature exists in this area, including a wide exploration of various types of basis expansions. For the purpose of this book, we do not delve into this discussion further and refer the reader to other more extensive treatments of the subject \cite{ESL}.

\subsubsection{Choosing Knots}

To this point, we have taken for granted the choice of number and location of the so-called ``knots'' in our model. However, as one might imagine, this is not always a trivial task. Depending on the data, the ``knots'' can have almost as much influence on the fit as the choice of basis functions.

For the purpose of generic disease modeling, we advocate for an informed choice of knot locations. Namely, knot locations should be chosen \emph{a priori} to reflect expert knowledge about the disease of interest and its behavior as a function of some continuous variable. For example, in a recent study looking at global trends in mean systolic blood pressure as a function of age, Danaei \emph{et al} elected to use a cubic regression spline with knots located at ages 30 and 60 ($\xi_1 = 30$ and $\xi_2=60$) \citation{Danaei2011}. These choices reflect the expectation, based on literature and prior knowledge, that the behavior of mean systolic blood pressure as a function of age would be distinct in these intervals due to a) low blood pressure in young adults, and b) survivor effects in elderly populations.  

Although this approach of using expert knowledge to inform the number of knots and knot locations is practical and allows for users to deterimine critical features of the model, it is certainly not the only approach. Much literature is devoted to the choice of knot locations and the number of knots. We refer our readers to \cite{ESL, Wand2001} for further discussion of this topic.

\begin{figure}[T]
 \centering \includegraphics[scale=0.75]{splines_fig.pdf}
\caption{(Left) Polynomial regression fits to simulated data, and (Right) Regression Spline fits to simulated data.}
\label{splines_fig}
\end{figure}

\subsection{background on Gaussian processes and the Matern covariance
function}
Elaborating on the following facts: Wikipedia provides a fine background:
\begin{quote}
In probability theory and statistics a \emph{Gaussian process} is a
  stochastic process whose realizations consist of random variable
  associated with every point in a range of times (or of space) such
  that each such random variable has a normal distribution. Moreover,
  every finite collection of those random variables has a multivariate
  normal distribution.

Gaussian processes are important in statistical modeling because
of properties inherited from the normal distribution. For example, if
a random process is modeled as a Gaussian process, the distributions
of various derived quantities can be obtained explicitly. Such
quantities include: the average value of the process over a range of
times; the error in estimating the average using sample values at a
small set of times.

A Gaussian process is a stochastic process $\{X_t : t \in T\}$ for
which any finite linear combination of samples will be normally
distributed (or, more generally, any linear functional applied to the
sample function $X_t$ will give a normally distributed result).

Alternatively, a process is Gaussian if and only if for every finite
set of indices $t_{1,\ldots,k}$ in the index set $T$,
\[
 \vec{\mathbf{X}}_{t_1, \ldots, t_k} = (\mathbf{X}_{t_1}, \ldots, \mathbf{X}_{t_k})
\]

is a vector-valued Gaussian
random variable. Using characteristic functions of random variables, the
Gaussian property can be formulated as
follows: $\{X_t : t \in T\}$
is Gaussian if and only if, for every finite set of indices
$t_1, \ldots, t_k$, there are reals
$\sigma_{l j}$ with $\sigma_{ii} > 0$ and reals
$\mu_j$ such that

\[
\operatorname{E}\left(\exp\left(i \ \sum_{\ell=1}^k t_\ell
\ \mathbf{X}_{t_\ell}\right)\right) = \exp \left(-\frac{1}{2} \,
\sum_{\ell, j} \sigma_{\ell j} t_\ell t_j + i \sum_\ell \mu_\ell
t_\ell\right).
\]

The numbers $\sigma_{lj}$ and $\mu_j$ can be shown to be the
covariances and means of the variables in
the process \cite{WP:GP}.

The ``Mat\'{e}rn covariance'' (named after the Swedish forestry
statistician Bertil Mat\'{e}rn) is a covariance function used in
spatial statistics, geostatistics, machine learning, image analysis,
and other applications of multivariate statistical analysis on metric
spaces. It is commonly used to define the statistical covariance
between measurements made at two points that are $d$ units distant
from each other. Since the covariance only depends on distances
between points, it is stationary process. If the distance is Euclidean
distance, the Mat\'{e}rn covariance is also isotropic.

The Mat\'{e}rn covariance between two points separated by $d$ distance
units is given by
\[
\calC(d) =
\sigma^2\frac{1}{\Gamma(\nu)2^{\nu-1}}\Bigg(2\sqrt{\nu}\frac{d}{\rho}\Bigg)^\nu
K_\nu\Bigg(2\sqrt{\nu}\frac{d}{\rho}\Bigg),
\]

where $\Gamma$ is the gamma function, $K_\nu$ is the modified Bessel
function of the second kind, and $\rho$ and $\nu$ are non-negative
parameters of the covariance.

A Gaussian process with Mat\'{e}rn covariance has sample paths that are
$\lceil \nu-1 \rceil$ times differentiable. As $\nu\rightarrow\infty$,
the Mat\'{e}rn covariance converges to the squared exponential covariance
function
\[
C(d) = \sigma^2\exp(-d^2/\rho^2). \,
\]
When $\nu = 0.5$, the Mat\'{e}rn covariance is identical to the
exponential covariance function \cite{WP:Matern}.
\end{quote}

Following the conventions of the Mat\'{e}rn implementation in the PyMC GP
Package, I call $\sigma$ the amplitude, $\rho$ the scale, and $\nu$
the degree of differentiability.  Figure~\ref{TK} shows the way that
this model fits age-speicifc data for a range of model parameters.

FIGURE TK

The theoretical appeal of the GP model is that it is truely
non-parametric;  as the amount of input data increases, the age
pattern of the GP becomes appropriately more complex, with no
limitation (in theory) to how complicated a pattern it can represent.
There are two practical objections, however.  First, although the
model is theoretically unlimited in the complexity it can represent,
it is \emph{computationally} limited, in the sense that representing
the posterior of a GP conditioned on $n$ normally
distributed observations requires $\scO(n^3)$ time, which becomes
prohibitive for large datasets.  Second, and more importantly, the
epidemilogical data representing specific age-groups almost never
provides information on age groups smaller than one year (and this level
of precision only occurs in neonatal disease epidemiology).  This
means that the infinite flexibility of the GP model will never be
needed in age pattern modeling, at least in the settings I am
currently interested in.

Because the data is not rich enough to require a truely non-parametric
model, and the computational requirements of the GP model are quite
high, I have drawn on elements of GP modeling and combined them with
elements of
spline modeling, matched to the data and also to the the implications
of the simplifying assumptions made in
Chapter~\ref{theory-forward_sim-compartmental_model-simplying_assumptions}
about the piecewise constant nature of the rates in the system of
differential equations.  For incidence, remission, and excess
mortality, I developed a prior distribution that could be called a
``piecewise constant Gaussian process'' (PCGP), with knots chosen
based on expert knowledge of the epidemiology of the disease under
consideration.  The mathematically precise definition will be
developed below, and Figure~\ref{TK1} shows the way this model fits
age-specific data for a range of model parameters.

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{smoothness_zero_priors.pdf}
\end{center}
\caption{The piecewise constant Gaussian process (PCGP) model with
  knots at TK for a range of Mat\'{e}rn parameters.  Note that the
  differentiability parameter of the Mat\'{e}rn covariance function
  has little effect in this setting, because the piecewise constant
  spline already imposes a particular pattern of local smoothness.}
\label{TK1}
\end{figure}

For modeling the age pattern of prevalence rates, I developed a
``piecewise linear Gaussian process'' (PLGP) analogous to the
PCGP. This balances theoretically appealing GP modeling with the
computational efficiency issues mentioned above, as well as a related
issue: in the systems dynamics model, the prevalence of the system is
produced as the solution of a system of differential equations, and
solving this system has high computational cost.  To make the
computation managable, I solve the differential equations only for
knots of the spline and then use linear interpolation to fill in
prevalence values between the knots.  Figure~\ref{TK} shows the way
that this model fits the same age-specific data used in
Figure~\ref{TK1}.

\begin{center}
\includegraphics[width=\textwidth]{smoothness_linear_priors.pdf}
\end{center}

Before moving to the precise mathematical definitoins of the PCGP and
PLGP distributions, in Figure~\ref{TK} I've attempted to demonstrate
the utility of this sort of modeling in representing a wide variety of
epidemiological age patterns.

Examples TK, ADHA, Anxiety, Cannabis, Dementia.

\subsection{Precise definitions}
In both the case of the PCGP and PLGP, I have combined the
semi-parametric functional form of a spline with the Mat\'{e}rn
covariance function, inspired from Gaussian process theory, by using a
variance/covariance matrix derived from the Mat\'{e}rn covariance function
in a Multivariate Normal prior on the knots of the piecewise constant
spline.

For a set of knots $\scA = \{a_0, a_1, \ldots, a_A\}$, with $0 = a_0 < a_1 <
\ldots , a_A\}$, the function $\boldpi(a)$ is \emph{piecewise
  constant} if $\boldpi(a) = \boldpi(a')$ for all $a, a'$ with $a_i
\leq a, a' < a_{i+1}$ for some $i$.  The PCGP model with knots $\scA$
is defined by
\begin{align*}
\boldpi(a_0), \ldots, \boldpi(a_A) \given \mu, \rho &\sim \Normal(\mu, \scC_\rho);\\
\log \mu &\sim \Normal(0, 2^2);\\
\calC &= \Matern(\nu, \sigma, \rho).\\
\end{align*}

Here I consider $\rho$ and $\mu$ hyper-priors, while $\nu$ I fix at
$2$ as a model parameter that makes little difference.  In practice, I
have found it sufficient to choose $\rho$ from $3$ possibilities corresponding
expert belief a priori that the age pattern smoothness is ``slightly'',
``moderately'', or ``very'' smooth.
Unfortunately, experts do not have an intuitive understanding of
$\rho$. Figure~\ref{theory-age_pattern_model-smoothness_priors} is
intended to help build intuition. The autocovariance plot shows how a
slight smoothing prior of $\rho=50$ leads to a prior where the value
of $f$ at age $a$ explains $50\%$ of the variation in $f$ at age
$a+TK$.  

\begin{figure}[h]
\begin{center}
\includegraphics[width=\textwidth]{smoothness_priors.pdf}
\includegraphics[width=\textwidth]{smoothness_covariance.pdf}
\end{center}
\caption{TK Figure on slightly, moderately, and very smooth priors.}
\label{theory-age_pattern_model-smoothness_priors}
\end{figure}
\subsection{Extensions}
Tk Special treatment of the prevalence prior is still on control
points of spline, but age pattern is from linear interpolation, since
the differential equations are more accurately approximated by this
than by a (continuous) piecewise constant function.

TK Special treatment for other derived values, since they are
combinations of continuous piecewise linear and piecewise constant
functions, they would end up being non-continuous piecewise linear
functions.  Since this is confusing, they are instead modeling as
piecewise constant functions, but with knots at the midpoints of the
knots for incidence, remission, and mortality.

TK Pitfalls of combining the smoothness constraints (?)

\subsection{Additional priors on age patterns}
A benefit of this Bayesian approach to age-pattern modeling is the
simplicity of adding additional constraints to the age-pattern prior
distribution.  For example, if the epidemiology of disease is such
that the prevalence level must be zero before a certain age (as is the
case in some psychological disorders) this can easily be incorporated.
There are four types of additional priors on age patterns that will
come up frequently in the applications later in this book: level bound
priors, level value priors, monotonicity priors, and convexity priors.

TK examples of each of these priors, together with mathematically
precise definitoin and examples of where it can come up and what it
does to change the results.

TK Future work: Unimodal priors [ref TK].  Data driven hyper-priors
for GP.  More advanced integration to lift piecewise constant
requirement on flows.

TK Future work 2: Extend to time/age models.

