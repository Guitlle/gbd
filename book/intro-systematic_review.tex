\section{From systematic review to metaregression}
To put the descriptive epidemiological metaregression framework
developed in this book in its historical context, we will now
provide a brief overview and introduction to meta-analysis and
systematic review.

Meta-analysis combines the results of several studies that address a
set of related research hypotheses. In its simplest form, this
technique identifies a common measure of interest in all studies, for
which a weighted average might be the output of the meta-analysis.
For example, the weighting could be related to sample sizes within the individual
studies.

The history of meta-analysis often begins with the work of Karl
Pearson.  In 1904, the British military commissioned Pearson to
evaluate the military's typhoid inoculation
campaigns.\cite{Pearson_Report_1904} Pearson obtained data on typhoid
inoculation and mortality from two studies, one from India and one
from South Africa, but determined that both
sample sizes were too small to permit a reliable analysis. To increase the sample
size, he combined the data and thus embarked on the first
meta-analysis in public health. Unfortunately, this landmark study concluded little.
With such heterogeneous data and irregular results, Pearson found
it problematic assigning how much weight should be attributed to
different results.  Despite its inauspicious beginning, meta-analysis
continued to develop.

%% In 1935, Ronald Fisher published the \emph{Design of
%%   Experiments} in which he made fundamental contributions to the
%% statistical theory underlying clinical trials. He also included a
%% meta-analysis in the textbook that combined data from multiple studies
%% to demonstrate that the effect of fertilizer varies over time and
%% geography. \cite{Fisher_Design_1935,O'Rourke_An_2007} After Fisher, statisticians began
%% to develop more sophisticated techniques to combine studies, for
%% instance, by building models that allowed data from different analyses to
%% have different variances and thus to be averaged together with
%% different weights.

The technique of systematic review has developed extensively since Pearson's time. The
sheer number of publications every year has forced researchers to
devise new ways to summarize and synthesize the torrent of data. From
1907, three years after the first meta-analysis, to 2007, the number of
scientific publications has exploded. The number of abstracts compiled by the
American Chemical Society has grown at $4.6$\% per year over that
$100$-year period. The number of publications compiled by the American Mathematical
Society has grown at $5.9$\% per year.  The number of publications in Compendex, a
database of engineering studies, has grown at $3.9$\% per year.
\cite{Larsen_Rate_2010} PubMed, the largest database of biomedical
literature in the world, now contains more than $21$ million citations.
\cite{us_national_library_of_medicine_national_institutes_of_health_pubmed_2012} Despite this growth in publications, data are
as heterogeneous and irregular as ever. This challenge certainly remains
for data in descriptive epidemiology. Integrative systems modeling
provides a framework to get the most information out of these disparate data.

As the number of scientific publications grew, identifying various
sources to synthesize in a meta-analysis became a formidable task in
its own right. This challenge led to the formalization of the process
for identifying sources and the to development of systematic review.
The Cochrane Collaboration is a
group of over $28,000$ volunteers who review data from randomized
control trials of health interventions.\cite{_cochrane_2012} In addition to the valuable information
they provide on the efficacy of a wide range of interventions, they have
created a detailed handbook for conducting systematic
reviews. The Cochrane Collaboration defines ``systematic review'' as the
methodic and explicit identification, selection, appraisal, collection,
and analysis of relevant research.  Meta-analysis then is defined as the use of statistical
techniques to combine the results of studies from a systematic review.\cite{Green_Systematic_2005}

The Preferred Reporting Items for Systematic Reviews and Meta-analyses
(PRISMA) group has also developed guidance for systematic reviews by
standardizing the steps involved in a modern approach to
the procedure.\cite{moher_preferred_2009} PRISMA divides the systematic
review process into four stages: Identification, Screening,
Eligibility, and Included.  In the Identification stage, the reviewer
finds citations for studies by searching databases like PubMed and by
contacting individual researchers and institutions. The reviewer uses
a specific set of keywords for the database search in order to make
that search transparent and replicable. In the Screening stage, the
reviewer removes duplicated and unusable data. In the Eligibility stage,
the reviewer excludes articles that do not match the explicit criteria
for inclusion in the study. For instance, some systematic reviews in
epidemiology only include evidence from randomized control trials and
exclude observational data. In the Included stage, the reviewer
finalizes the studies used for the systematic review.

Meta-analyses rely critically on the systematic review procedure. Here
it is convenient to follow the terminology used by the Cochrane
Collaboration and PRISMA and use ``meta-analysis'' to refer to
statistical methods for combining evidence.  This provides a clear
separation between systematic review and meta-analysis and also divides
meta-analysis from nonstatistical approaches of ``research
synthesis'' or ``evidence synthesis,'' such as combining information
from qualitative studies.

As part of GBD 2010, groups of disease experts implemented
this process for each disease and risk factor to be
included. Because of the nature of data sources for descriptive
epidemiology, the effort to capture data from nonpublished sources
was much more intense than in the traditional review of
intervention studies in the Cochrane library.  For some diseases, such
as schistosomiasis, the vast majority of data obtained (more than
98\%) came from studies that are not in the peer-reviewed literature.
Regardless of the primary source of epidemiological measurements, the
methodological challenge was then to take the resulting data as input
to generate estimates of epidemiological parameters of interest such
as incidence, prevalence, and duration.

By far the most common use of meta-analytic techniques in epidemiology is to estimate
the effect size of an intervention.  By pooling all studies of the
intervention effect, the meta-analysis provides a more precise
estimate of effect size than that found in any individual single
study.

The Cochrane guidelines caution not to compare studies with very
different outcome measures of effect or very different patient
populations when conducting a
meta-analysis.\cite{_cochrane_2012} This is a subtle point
and is more clearly developed in the effect-size meta-analysis realm
than in the meta-analysis of descriptive epidemiological data.  In
fact, comparing studies with different outcome measures is at the
heart of this book, which develops a method for comparing the results
of descriptive epidemiological studies of disease prevalence,
incidence, remission, and mortality risk that are focused on
subpopulations from varying age groups, sexes, regions, and time
periods.

Our framework is not without precedent, however.  The next section discusses the
legacy of ``generic disease modeling,'' upon which our integrative approach
to descriptive epidemiological metaregression builds.



