\section{History of Generic Disease Modeling}
TK introductary words explaining why modeling is necessary, make the
case for models, to deal with sparse, noisy, inconsistent data.

The precursor to the first DisMod, the Harvard
Incidence-Prevalence Model, was a spreadsheet implemented in Lotus 123
(Murray \& Lopez, 1994). TK equations describing this model.

DisMod I, the software used for the first
Global Burden of Disease Study, was a C++ program that ran in
Microsoft Windows 3.1 on a desktop computer (Murray \& Lopez, The
global burden of disease: a comprehensive assessment of mortality and
disability from diseases, injuries, and risk factors in 1990 and
projected to 2020, 1996). TK equations describing this model, highlight differences between this and HIP model.

DisMod II provided more control over inputs
to the model and provided a graphical user interface (Barendregt,
Oortmarssen, Vos, \& Murray, 2003). TK equations and discussion of differences between this and DM II.

TK some words on the other model by Barendregt that is compared to DisMod in some of the literature of the last decade.

DisMod III, the latest member of
the DisMod family and the subject of this book, consists of an
interactive web interface to a computational engine that runs on a
roughly 2000 core computer cluster. From a spreadsheet solving a
simple system of differential equations to a computer cluster
performing Markov Chain Monte Carlo to compute the probability
distributions of epidemiological parameters in a dynamic system,
generic disease modeling has come a long way.

Computing power has increased dramatically over the 20 year period
that the DisMod family of generic disease modeling software has
evolved. 

Much of the initial work on generic disease modeling was pioneered by
Christopher Murray and Alan Lopez as part of the original Global
Burden of Disease Study (GBD 1990) commissioned by the World Bank in
1991 (IHME, 2011). One of their first models was the Harvard
Incidence-Prevalence Model. The model involved constructing a life
table to simulate a cohort exposed to a set of age-specific incidence,
remission, case fatality and background mortality hazards. At each
year in the life table, the model simulated a simple 3-compartment
model to provide estimates of the number susceptible, the number of
cases and the number of deaths to input into the life table for the
next year (Murray \& Lopez, Quantifying disability: data, methods, and
results, 1994). Murray and Lopez delineated 3 purposes for this model:
1) To estimate incidence and duration by age if prevalence is known,
2) To estimate prevalence when incidence is known and 3) To estimate
death attributable to different causes of diseases. The estimation
procedure in all 3 cases involved setting the unknown parameters to a
level deemed reasonable by the researchers, running the model with
these new parameters, evaluating the plausibility of the results, and
then repeating the entire process with a modified set of parameters
until a plausible and consistent set of estimates are obtained.

TK figure showing three compartment model

The first DisMod, used for GBD 1990, adhered closely to the modeling
strategy of the Harvard Incidence-Prevalence Model (Murray \& Lopez,
The global burden of disease: a comprehensive assessment of mortality
and disability from diseases, injuries, and risk factors in 1990 and
projected to 2020, 1996). It was developed by Murray and Lopez along
with colleagues in the Burden of Disease Unit at the Harvard Center
for Population and Development Studies. It used a 4-compartment
generic disease model, where members of the population could move
from the Susceptibles compartment to the Cases
compartment if they contracted the disease (and back if they remitted)
to the Cause-specific deaths compartment if they died of the
disease or to the Deaths from general mortality compartment if
they died of general, background mortality. DisMod I allowed a user to
specify a set of age-specific incidence, remission and case-fatality
rates for a specific disease, region and sex. It then would solve the
differential equations corresponding to the 4-compartment model with
the user-specified hazards.

TK figure showing four compartment model

For the second iteration of the Global Burden of Disease Study, Jan
Bardendregt and colleagues developed a new implementation of DisMod,
which provided a stable user-interface and sufficient documentation
for the application to be used widely beyond the initial analysis
(Barendregt, Oortmarssen, Vos, \& Murray, 2003). DisMod II, like the
original DisMod focused on data confrontation, and specialized in
combining single best-estimates of individual disease parameters, such
as incidence, prevalence, remission, and case-fatality to produce a
set of internally consistent estimates for a single time, place, and
sex.

TK is there any difference between DM I and DM II besides
implementation?  This doesn't make it clear.

As is often the case in science, a very similar approach had been
developed previously, by researchers, totally unknown to the WHO
researchers, at the International Institute for Applied Systems
Analysis in Austria in the 1970s. These researchers worked on
developing a generic Healthcare System Model to improve management and
planning in the health sector. One component of this model was a
computer program to estimate prevalence from incidence (Klementiev,
1977). That program evolved a population exposed to age-specific
incidences of disease and death through time. It was applied to
estimate the prevalence of malignant neoplasm in Austria, France and
Belgium.

TK more words on how this model differs: no remission, and increasing
hazard with tau, figure showing the compartmental model behind it.

The generic disease modeling approach was distributed without cost by
WHO through the DisMod II software tool, and used widely in burden of
disease studies. These studies adopted the methodology of the global
study, but aimed to assess burden at a level of detail more relevant
for national policymakers. Over 2 dozen countries have undertaken a
national burden of disease study (WHO, 2003). The first generation of
these studies, which used the same valuations for the disability
weight of living in different health states as the original Global
Burden of Disease study, included studies in Mexico, Chile, Columbia
and Mauritius (Lozano, Murray, Frenk, \& Bobadilla, 1995) (Concha,
Aguilera, \& Albala, 1996) (Salud, 1994) (Vos, Timaeus, Gareeboo,
Roussety, Huttly, \& Murray, 1995). The Mauritius Burden of Disease
Study was led by Theo Vos, who became a key contributer to later
iterations of DisMod. The Australian Burden of Disease Study is a more
recent example of national studies using DisMod to make data on
epidemiological parameters consistent (Mathers, Vos, Stevenson, \&
Begg, 2001).

Despite its wide application, there were some feature
requests and methodological concerns that developed over the decade
that DisMod II reigned as the standard approach for disease burden
estimation. Chief among them was the difficultly in producing consistent estimates
that exhibited ``face validity'', for example age patterns that
increased monotonically as a function of age. Despite strongly held
prior beliefs on the part of domain experts, it was not uncommon for
the data to show oscillations as a function of age, due to the
contortions that DisMod II would subject rates to in order to produce
consistent estimates as close to the inconsistent input estimates as
possible.

Another important challenge in the DisMod II workflow was the
production of single best estimates for at least 3 independent rates
in the first place. As mentioned in section TK, for common diseases
like TK, there are over TK studies of disease prevalence that met the
inclusion criteria of a recent systematic literature review. DisMod II
provided no guidance on how to go from this large collection of
estimates, often for incommensurate age intervals, to a single best
estimate of disease prevalence.

Finally, although DisMod II excelled in providing consistent estimates
from the confrontation of inconsistent estimates of several disease
parameters for a single place and time, it was laborious on the part
of the data analyst to produce comparable estimates for a variety of
different places and times. In the Global Burden of Disease 2010
Study, there are 21 geographic regions to produce estimates for, at 3
different points in time, for males and females. Even an analysis that
is trivial for one region/time/sex becomes burdensome when it must be
replicated 126 times.

In 2008, work on DisMod III was initiated by Abraham Flaxman. The
project was inspired by the previous generations of generic disease
models developed in the past global and national burden of disease
studies, as well as work on mortality estimation and prediction by
Girosi and King, which used Bayesian methods to estimate age patterns
of mortality simultaneously for multiple regions of the world. The
model was developed in collaboration with the many disease experts who
volunteered to help in the GBD 2010 study. The expert contributors in
the mental disorders group and substance dependence group produced
preliminary results from their systematic reviews of the published and
unpublished literatures that became early test examples for the
development of the new system. A synthetic example disease along with
simulated noisy and sparse data on that disease was also created to
aid in testing.

The broad principle behind this next generation of generic disease
modeling can be characterized as connecting a system dynamics model to
a statistical model, so that instead of doing forward simulation, as
is traditionally the case in system dynamics modeling, the model
describes an inverse problem. This approach is termed \emph{integrative
systems modeling} and its past applications are reviewed in the next
section.

\section{Integrative systems modeling}
A vast body of literature exists on compartmental modeling and its
wide applicability to modeling the dynamics of complex systems
(Forrester, 1968) (Meadows, 2008) (Bossel, 2007).  TK more words in
the way of a general introduction to this idea.  Something about
Forrester's outsider models of epi, something about the introductory
textbook in environmental science Consider a spherical cow, etc.

\subsection{Compartmental models in epidemiology}
In epidemiology,
compartmental models are often constructed to simulate infectious
disease dynamics (May \& Anderson, 1991). The classic SIR model
evolves a population through a Susceptible compartment to an Infected
compartment to a Recovered compartment (Kermack \& McKendrick,
1927). Infection dynamics are captured by making the amount of mass
that moves from the Susceptible compartment to the Infected
compartment dependent on the product of the masses in the two
compartments. This dependence implies that the number of new
infections will increase with the number of current
infections. Extensions of this basic model abound (Daley \& Gani,
2005) (Brauer \& Castillo-Chavez, 2001). The transition parameters in
this class of compartmental models, incidence and remission for
instance in the case of the SIR model, are usually set based on
extracting point estimates of the parameters from literature
reviews. Uncertainty is usually assessed based on a sensitivity
analysis that solves the compartmental model for the range of
parameter estimates found in the literature (UCLA disease modeler who
started latin hypercube sampling) (Nagelkerke, Jha, Vlas, Korenromp,
Moses, \& Blanchard, 2002) (Brandeau, Owens, Sox, \& Wachter, 1993)
(Broutin, Viboud, Grenfell, Miller, \& Rohani, 2010). 

TK less harsh version of the following paragraph:
In the vast
majority of statistical analyses, this estimation approach would not
be considered sufficient. Instead, the analyst would attempt to find
the parameters that, for instance, maximized the likelihood of a set
of data samples of the parameter values. This statistical approach has
the advantage that uncertainty can be rigorously quantified and an
optimal estimate can be identified based on a transparent
model. 

Combining these approaches is currently the subject of basic research.  TK references to the ``plug-and-play'' approach to statistical inference for mechanistic models.

Advances in statistical modeling and computation have allowed
increasingly sophisticated models to be fit to data. These advances
have spawned a new modeling approach that seeks to provide more
reliable point estimates and estimates of uncertainty for parameters
in compartmental models. This new approach, integrative systems
modeling, connects a system dynamics model to a statistical model so
that parameters in the system can be estimated in a statistical
framework without sacrificing the structure provided by the dynamical
model.

The analyst building a statistical model has a rich vocabulary with
which to describe the data generating process of interest. Data can
come from a range of distributions. Hierarchical data can be expressed
via random effects and smooth data through the correlation structure
of a covariance matrix. In the most mature forms of integrated systems
modeling, this rich vocabulary is made available for estimating
parameters in a compartmental model. DisMod III is a prime example of
connecting a sophisticated statistical model to the generic disease
dynamics model. The complexity of the statistical model and the
complexity of the underlying dynamic systems model vary across
different applications.

\subsection{Compartmental models in pharmacokinetics}
The field of pharmacokinetics and pharmacodynamics (PK/PD) provides
examples of connecting a sophisticated statistical model to a
compartmental model outside of the domain of generic disease modeling.

Pharmacokinetics is the study of how drugs get absorbed and
distributed in the body. Pharmacodynamics is the study of the effect
of drugs on the body. Much of the content of these two fields overlap
so they are often studied together. Within PK/PD, the field of
population pharmacokinetics attempts to understand the sources of
variability in drug response among individuals (Yuh, et al.,
1994). Because clinical trials provide data on only a small subset of
the target patient population and at small sample sizes, it is often
difficult to estimate variation among individuals without imposing
additional structure on the estimation problem. In 1972, the field of
population pharmacokinetics began in earnest when nonlinear mixed
effects modeling was proposed as a solution to the limited clinical
data (Sheiner, Rosenberg, \& Melmon, 1972). The techniques that have
emerged in this field are mathematically identical to the new
generation of generic disease modeling illustrated by DisMod
III. Analysts in population pharmacokinetics connect a random effects
model of patients within a study (the statistical model) to a
compartmental model that describes the process of a drug's
absorption in the body (the dynamic systems model).

Analogous to the advent of the DisMod software for simulating and
estimating generic disease models, many different software packages
have arisen to help conduct analyses in population
pharmacokinetics. NONMEM, which developed at the UCSF, was one of the
first (Beal, Sheiner, Boeckmann, \& Bauer, 2009). SAAM II, a computer
tool for the simulation, analysis and modeling of pharmacokinetic
data, also allows users to fit compartmental models of the drug
response to clinical data using the integrative systems modeling
approach (Barrett, et al., 1998). One of the developers of that
software, Brad Bell, has also contributed to the development of the
DisMod family of software. The further exchange of insights in
population pharmacokinetics and in generic disease modeling will
likely benefit both fields in the future.


