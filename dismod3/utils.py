import pylab as pl
import numpy as np
import pymc as mc
from pymc import gp
from ctypes import *
from settings import *

try:
    from gbd.settings import DEBUG_TO_STDOUT
except:
    DEBUG_TO_STDOUT = True

def debug(string):
    """ Print string, or output it in the appropriate way for the
    environment (i.e. don't output it at all on production server).
    """
    if DEBUG_TO_STDOUT:
        import sys
        print string
        sys.stdout.flush()


def trim(x, a, b):
    return np.maximum(a, np.minimum(b, x))

def const_func(x, c):
    """
    useful function for defining a non-informative
    prior on a Gaussian process
    >>> const_func([1,2,3], 17.0)
    [17., 17., 17.]
    """
    return np.zeros(len(x)) + c

def uninformative_prior_gp(c=-10.,  diff_degree=2., amp=100., scale=200.):
    """
    return mean and covariance objects for an uninformative prior on
    the age-specific rate
    """
    M = gp.Mean(const_func, c=c)
    C = gp.Covariance(gp.matern.euclidean, diff_degree=diff_degree,
                      amp=amp, scale=scale)

    return M, C

def spline_interpolate(in_mesh, values, out_mesh):
    from scipy.interpolate import interp1d
    f = interp1d(in_mesh, values, kind='linear')
    return f(out_mesh)

# def gp_interpolate(in_mesh, values, out_mesh):
#     """
#     interpolate a set of values given at
#     points on in_mesh to find values on
#     out_mesh.
#     """
#     M, C = uninformative_prior_gp()
#     gp.observe(M, C, in_mesh, values)
#     return M(out_mesh)

def interpolate(in_mesh, values, out_mesh):
    """
    wrapper so that it is only necessary to
    make one change to try different interpolation
    methods
    """
    return spline_interpolate(in_mesh, values, out_mesh)

def rate_for_range(raw_rate,age_indices,age_weights):
    """
    calculate rate for a given age-range,
    using the age-specific population numbers
    given by entries in years t0-t1 of pop_table,
    for given country and sex

    age_indices is a list of which indices of the raw rate
    should be used in the age weighted average (pre-computed
    because this is called in the inner loop of the mcmc)
    """
    age_adjusted_rate = np.dot(raw_rate[age_indices], age_weights)
    return age_adjusted_rate

def gbd_keys(type_list=stoch_var_types,
             region_list=gbd_regions,
             year_list=gbd_years,
             sex_list=gbd_sexes):
    """ Make a list of gbd keys for the type, region, year, and sex
    specified

    Parameters
    ----------
    type_list : list, optional, subset of ['incidence', 'remission', 'excess-mortality']
    region_list : list, optional, subset of 21 GBD regions
    year_list : list, optional, subset of ['1990', '2005']
    sex_list : list, optional, subset of ['male', 'female']

    Results
    -------
    A list of gbd keys corresponding to all combinations of list
    items.
    """
    key_list = []

    # special case: prevalence is controlled by incidence, remission,
    # and excess-mortality
    if type_list == [ 'prevalence' ]:
        types = [clean(t) for t in output_data_types]
        
    for t in type_list:
        for r in region_list:
            for y in year_list:
                for s in sex_list:
                    key_list.append(gbd_key_for(t, r, y, s))
    return key_list

def clean(s):
    """ Return a 'clean' version of a string, suitable for using as a hash
    string or a class attribute.
    """
    s = s.strip()
    s = s.lower()
    s = s.replace(',', '')
    s = s.replace('/', '_')
    s = s.replace(' ', '_')
    s = s.replace('(', '')
    s = s.replace(')', '')
    return s

def gbd_key_for(type, region, year, sex):
    """ Make a human-readable string that can be used as a key for
    storing estimates for the given type/region/year/sex.
    """
    return KEY_DELIM_CHAR.join([clean(type), clean(region),
                                str(year), clean(sex)])
    
def type_region_year_sex_from_key(key):
    ret = key.split(KEY_DELIM_CHAR)
    if len(ret) == 4:
        return ret
    else:
        return ['unknown', 'world', '1997', 'total']
    

def indices_for_range(age_mesh, age_start, age_end):
    return [ ii for ii, a in enumerate(age_mesh) if a >= age_start and a <= age_end ]

def prior_vals(dm, type):
    """ Estimate the prior distribution on param_age_mesh for a particular type

    Parameters
    ----------
    dm : DiseaseJson
    type : str, one of 'prevalence', 'incidence', 'remission', 'excess-mortality'

    Results
    -------
    vars : dict of stochastics generated by logit_normal_model
    
    """
    import random
    import dismod3.neg_binom_model as model

    data = [d for d in dm.data if clean(d['data_type']).find(type) != -1 and not d.get('ignore') != 1]

    dm.clear_empirical_prior()
    dm.fit_initial_estimate(type, data)
    if len(data) >= 8:
        random.seed(12345)
        data = random.sample(data, 8)

    X_region, X_study = model.regional_covariates('none', dm.get_covariates())
    est_mesh = dm.get_estimate_age_mesh()
    prior_dict = dict(alpha=np.zeros(len(X_region)),
                      beta=np.zeros(len(X_study)),
                      gamma=-10*np.ones(len(est_mesh)),
                      sigma_alpha=[1.],
                      sigma_beta=[1.],
                      sigma_gamma=[1.],
                      delta=100.,
                      sigma_delta=1.)

    vars = model.setup(dm, key=type, data_list=data, emp_prior=prior_dict)

    mc.MAP(vars).fit(method='fmin_powell', tol=.1, iterlim=100)
    mc.MCMC(vars).sample(1)
    return vars

def prior_dict_to_str(pd):
    """ Generate a string suitable for passing to generate_prior_potentials
    from a prior dictionary

    Input
    -----
    pd : dict

    Notes
    -----
    This is a bit brittle, and a lot of duplicated code.  It should be rethought one day.
    """
    prior_str = ''

    smooth_str = {
        'No Prior': '',
        'Slightly': 'smooth 10',
        'Moderately': 'smooth 20',
        'Very': 'smooth 40',
        }

    het_str = {
        'Unusable': 'heterogeneity 0 0,',
        'Slightly': 'heterogeneity 100 1,',
        'Moderately': 'heterogeneity 10 .1,',
        'Very': 'heterogeneity 2 .01,',
        }

    #prior_str += smooth_str[pd.get('smoothness', 'No Prior')]
    prior_str += smooth_str[pd.get('smoothness', {}).get('amount', 'No Prior')]
    if prior_str != '':
        v0 = int(pd.get('smoothness', {}).get('age_start', 0))
        v1 = int(pd.get('smoothness', {}).get('age_end', 0))
        prior_str += ' %d %d,' % (v0, v1)
    prior_str += het_str[pd.get('heterogeneity', 'Very')]

    lv = float(pd.get('level_value', {}).get('value',0.))
    v = int(pd.get('level_value', {}).get('age_before',0)) - 1
    if v >= 0:
        prior_str += 'level_value %f 0 %d,' % (lv, v)
    
    v = int(pd.get('level_value', {}).get('age_after',100)) + 1
    if v <= 100:
        prior_str += 'level_value %f %d 100,' % (lv, v)

    v = float(pd.get('level_bounds', {}).get('upper',0.))
    if v > 0.:
        prior_str += 'at_most %f,' % v

    v = float(pd.get('level_bounds', {}).get('lower', 0.))
    if v > 0.:
        prior_str += 'at_least %f,' % v

    v0 = int(pd.get('increasing', {}).get('age_start', 0))
    v1 = int(pd.get('increasing', {}).get('age_end', 0))
    if v0 < v1:
        prior_str += 'increasing %d %d,' % (v0, v1)

    v0 = int(pd.get('decreasing', {}).get('age_start', 0))
    v1 = int(pd.get('decreasing', {}).get('age_end', 0))
    if v0 < v1:
        prior_str += 'decreasing %d %d,' % (v0, v1)

    v0 = int(pd.get('unimodal', {}).get('age_start', 0))
    v1 = int(pd.get('unimodal', {}).get('age_end', 0))
    if v0 < v1:
        prior_str += 'unimodal %d %d,' % (v0, v1)

    return prior_str

def generate_prior_potentials(rate_vars, prior_str, age_mesh):
    """
    augment the rate_vars dict to include a list of potentials that model priors on  rate_vars['rate_stoch']

    prior_str may have entries in the following format:
      smooth <tau> [<age_start> <age_end>]
      zero <age_start> <age_end>
      confidence <mean> <tau>
      increasing <age_start> <age_end>
      decreasing <age_start> <age_end>
      convex_up <age_start> <age_end>
      convex_down <age_start> <age_end>
      unimodal <age_start> <age_end>
      value <mean> <tau> [<age_start> <age_end>]
      at_least <value>
      at_most <value>
      max_at_most <value>
            
    for example: 'smooth .1, zero 0 5, zero 95 100'

    age_mesh[i] indicates what age the value of rate[i] corresponds to
    """

    def derivative_sign_prior(rate, prior, deriv, sign):
        age_start = int(prior[1])
        age_end = int(prior[2])
        age_indices = indices_for_range(age_mesh, age_start, age_end)
        @mc.potential(name='deriv_sign_{%d,%d,%d,%d}^%s' % (deriv, sign, age_start, age_end, rate))
        def deriv_sign_rate(f=rate,
                            age_indices=age_indices,
                            tau=1.e14,
                            deriv=deriv, sign=sign):
            df = np.diff(f[age_indices], deriv)
            return mc.normal_like(np.abs(df) * (sign * df < 0), 0., tau)
        return [deriv_sign_rate]

    priors = []
    rate = rate_vars['rate_stoch']
    rate_vars['bounds_func'] = lambda f, age: f
    for line in prior_str.split(PRIOR_SEP_STR):
        prior = line.strip().split()
        if len(prior) == 0:
            continue
        if prior[0] == 'smooth':
            scale = float(prior[1])

            if len(prior) == 4:
                age_start = int(prior[2])
                age_end = int(prior[3])
            else:
                age_start = 0
                age_end = MAX_AGE

            # can't smooth last age of rate, since we need ratio f[a+1]/f[a]
            if age_end == len(rate.value)-1:
                age_end -= 1
                
            age_indices = indices_for_range(age_mesh, age_start, age_end)
            
            from pymc.gp.cov_funs import matern
            a = np.atleast_2d(age_indices).T
            C = matern.euclidean(a, a, diff_degree = 2, amp = 1., scale = scale)
            @mc.potential(name='smooth_{%d,%d}^%s' % (age_start, age_end, str(rate)))
            def smooth_rate(f=rate, age_indices=age_indices, C=C):
                log_rate = np.log(f + 1.e-8)
                return mc.mv_normal_cov_like(log_rate[age_indices],
                                             -5*np.ones_like(age_indices),
                                             C=C)
            priors += [smooth_rate]

        elif prior[0] == 'heterogeneity':
            # prior affects dispersion term of model; handle as a special case
            continue

        elif prior[0] == 'increasing':
            priors += derivative_sign_prior(rate, prior, deriv=1, sign=1)
        elif prior[0] == 'decreasing':
            priors += derivative_sign_prior(rate, prior, deriv=1, sign=-1)
        elif prior[0] == 'convex_down':
            priors += derivative_sign_prior(rate, prior, deriv=2, sign=-1)
        elif prior[0] == 'convex_up':
            priors += derivative_sign_prior(rate, prior, deriv=2, sign=1)

        elif prior[0] == 'unimodal':
            age_start = int(prior[1])
            age_end = int(prior[2])
            age_indices = indices_for_range(age_mesh, age_start, age_end)

            @mc.potential(name='unimodal_{%d,%d}^%s' % (age_start, age_end, rate))
            def unimodal_rate(f=rate, age_indices=age_indices, tau=1.e5):
                df = np.diff(f[age_indices])
                sign_changes = pl.find((df[:-1] > NEARLY_ZERO) & (df[1:] < -NEARLY_ZERO))
                sign = np.ones(len(age_indices)-2)
                if len(sign_changes) > 0:
                    change_age = sign_changes[len(sign_changes)/2]
                    sign[change_age:] = -1.
                return -tau*np.dot(np.abs(df[:-1]), (sign * df[:-1] < 0))
            priors += [unimodal_rate]

        elif prior[0] == 'max_at_least':
            val = float(prior[1])

            @mc.potential(name='max_at_least_{%f}^{%s}' % (val, rate))
            def max_at_least(cur_max=rate, at_least=val, tau=(.001*val)**-2):
                return -tau * (cur_max - at_least)**2 * (cur_max < at_least)
            priors += [max_at_least]

        elif prior[0] == 'level_value':
            val = float(prior[1]) + 1.e-9

            if len(prior) == 4:
                age_start = int(prior[2])
                age_end = int(prior[3])
            else:
                age_start = 0
                age_end = MAX_AGE
            age_indices = indices_for_range(age_mesh, age_start, age_end)

            def new_bounds_func(f, age, val=val, age_start=age_start, age_end=age_end, prev_bounds_func=rate_vars['bounds_func']):
                age = np.array(age)
                return np.where((age >= age_start) * (age <= age_end), val, prev_bounds_func(f, age))
            rate_vars['bounds_func'] = new_bounds_func

        elif prior[0] == 'at_most':
            val = float(prior[1])

            def new_bounds_func(f, age, val=val, prev_bounds_func=rate_vars['bounds_func']):
                return np.minimum(prev_bounds_func(f, age), val)
            rate_vars['bounds_func'] = new_bounds_func

        elif prior[0] == 'at_least':
            val = float(prior[1])

            def new_bounds_func(f, age, val=val, prev_bounds_func=rate_vars['bounds_func']):
                return np.maximum(prev_bounds_func(f, age), val)
            rate_vars['bounds_func'] = new_bounds_func

        else:
            raise KeyError, 'Unrecognized prior: %s' % prior_str

    # update rate stoch with the bounds func from the priors
    @mc.deterministic(name='%s_w_bounds'%rate_vars['rate_stoch'].__name__)
    def mu_bounded(mu=rate_vars['rate_stoch'], bounds_func=rate_vars['bounds_func']):
        return bounds_func(mu, np.arange(101))  # FIXME: don't hardcode age range
    rate_vars['unbounded_rate'] = rate_vars['rate_stoch']
    rate_vars['rate_stoch'] = mu_bounded

    # add potential to encourage rate to look like level bounds
    @mc.potential(name='%s_potential'%rate_vars['rate_stoch'])
    def mu_potential(mu1=rate_vars['unbounded_rate'], mu2=rate_vars['rate_stoch']):
        return mc.normal_like(mu1, mu2, 1.0)
    rate_vars['rate_potential'] = mu_potential

    rate_vars['priors'] = priors

so = CDLL(LIB_PATH)

# Set up interface.
so.scpm.argtypes = [POINTER(c_double), POINTER(c_double), POINTER(c_double),
                    POINTER(c_double), POINTER(c_double), POINTER(c_int),
                    c_int, c_double, c_double, POINTER(c_double)]
so.scpm.restype  = POINTER(c_double)

so.obs.argtypes = [POINTER(c_double), POINTER(c_double), POINTER(c_double),
                   POINTER(c_double), POINTER(c_double), POINTER(c_double), 
                   POINTER(c_double), c_double, POINTER(c_int),
                   POINTER(c_double), c_int, c_int, c_int, c_int, POINTER(c_int)]
so.obs.restype  = c_double

# Call the function scpm.
def cscpm(SC_0, i, r, f, m_all_cause, age_mesh, step, NEARLY_ZERO):
    """Calculate SCpm

    Parameters:
    -----------
    SC_0 : float array[2]
    i : float array[est_age_mesh]
    r : float array[est_age_mesh]
    f : float array[est_age_mesh]
    m-all_cause : float array[est_age_mesh]
    age_mesh : int array[param_age_mesh]
    step : float > 0
    NEARLY_ZERO : float > 0

    Return:
    -------
    SCpm : float array[4, param_age_mesh]
    """
    doubleArray = c_double * len(SC_0)
    cSC_0 = doubleArray(* SC_0)
    doubleArray = c_double * len(i)
    ci = doubleArray(* i)
    doubleArray = c_double * len(r)
    cr = doubleArray(* r)
    doubleArray = c_double * len(f)
    cf = doubleArray(* f)
    doubleArray = c_double * len(m_all_cause)
    cm_all_cause = doubleArray(* m_all_cause)
    intArray = c_int * len(age_mesh)
    cage_mesh = intArray(* age_mesh)
    n = len(cage_mesh)
    buff = np.zeros(4 * n)
    doubleArray = c_double * len(buff)
    cbuff = doubleArray(* buff)
    result = so.scpm(cSC_0, ci, cr, cf, cm_all_cause, cage_mesh, n, step, NEARLY_ZERO, cbuff)
    a = np.zeros([4, n])
    for i in range(4):
        for j in range(n):
            a[i, j] = result[i * n + j]
    return a

# Call the function obs.
def cobs(value, N, Xa, Xb, alpha, beta, gamma, delta, age_indices, age_weights, lb):
    """Calculate likelihood

    Parameters:
    -----------
    value : float list[data_size]
    N : float array[data_size]
    Xa : float array[data_size, alpha_size]
    Xb : float list[data_size, beta_size]
    alpha : float array[alpha_size]
    beta : float array[beta_size]
    gamma : float array[est_age_mesh]
    delta : float
    age_indices : int list[data_size, study_age_size]
    age_weights : float list[data_size, study_age_size]

    Return:
    -------
    logp : float
    """
    doubleArray = c_double * len(value)
    cvalue = doubleArray(* value)
    doubleArray = c_double * len(N)
    cN = doubleArray(* N)
    Xa = np.array(Xa).ravel()
    doubleArray = c_double * len(Xa)
    cXa = doubleArray(* Xa)
    Xb = np.array(Xb).ravel()
    doubleArray = c_double * len(Xb)
    cXb = doubleArray(* Xb)
    doubleArray = c_double * len(alpha)
    calpha = doubleArray(* alpha)
    beta = np.atleast_1d(beta)
    doubleArray = c_double * len(beta)
    cbeta = doubleArray(* beta)
    doubleArray = c_double * len(gamma)
    cgamma = doubleArray(* gamma)
    indices = []
    for i in age_indices:
        for j in i:
            indices.append(j)
    intArray = c_int * len(indices)
    cage_indices = intArray(* indices)
    weights = []
    for i in age_weights:
        for j in i:
            weights.append(j)
    doubleArray = c_double * len(weights)
    cage_weights = doubleArray(* weights)
    ndata = len(cvalue)
    nalpha = len(calpha)
    nbeta = len(cbeta)
    ngamma = len(cgamma)
    ages = [len(a) for a in age_indices]
    intArray = c_int * len(ages)
    cages = intArray(* ages)
    result = so.obs(cvalue, cN, cXa, cXb, calpha, cbeta, cgamma, delta, cage_indices,
                    cage_weights, ndata, nalpha, nbeta, ngamma, cages, lb)
    return result




